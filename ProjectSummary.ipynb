{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Summary\n",
    "#### Devin Shirley, Madison Karlin, Katherine Koczwara, Melissa Stephens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "Blasted 'uniquetranscripts.fasta' in the 'BLAST_DNA_hits' repo with the following parameters: \n",
    "* nucleotide collection\n",
    "* normal defaults\n",
    "* highly similar sequence option\n",
    "\n",
    "Saved and downloaded hits tables to repo, see 'HitTable1',1-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "Using unix we made a table that includes the top hit for each transcript (6) \n",
    "* Chose with highest percent identity and highest max score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### pseudo unix code\n",
    "for files in 'all of the csvs'; get the top line of the document since it is sorted that way as a default, read just that line, move that to a file; repeat for each csv \n",
    "\n",
    "the script for this is 'top_hits.sh' saved in the 'BLAST_DNA_hits' repo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####Reads all of the .csv files in the repository, takes their first line\n",
    "#and moves them to a new file\n",
    "\n",
    "for file in *.csv; do head -1 $file | cat top_hits; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Notes\n",
    "The disovered accession number from the table was searched on its NCBI page we then found the protein under the CDS subheading which is hyperlinked, after clicking on it we could see the name of the protein which was used in part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "We searched the NCBI protein database (https://www.ncbi.nlm.nih.gov/protein) for protein from each top hit   \n",
    "* filtered by taxon\n",
    "    + View as a tree\n",
    "* Choose 10-20 protein sequences from closely related species (Muridae is family mice/rats are in)\n",
    "* Create 1 fasta file per transcript (6)\n",
    "Added each file to the 'BLAST_Proteins' repo\n",
    "    see Protein_1_Gluthanione....\n",
    "    Protein_2....\n",
    "    ....\n",
    "\n",
    "While doing this step we also did the further exploration steps for nonmammalls (fish,turtles,birds, etc) and primates (humans, apes) and added their protein fasta files to the repo\n",
    "\n",
    "For each group we saved the protein files to a repo inside the 'BLAST_Proteins' repo\n",
    "* Mice/Rodents/Muridae to the 'Rodent_Protein_Hits' repo\n",
    "* Humans/Apes to the 'Primate_Protein_Hits' repo\n",
    "* Birds/Lizards/Turtles/Fish to the 'Nonmammalian_Protein_Hits' repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "We wrote a python script that translates RNAseq data to amino acid data, see 'aminoacid_seq.py' in the 'RNAseq_data' repo\n",
    "* input .fasta file \n",
    "* output .protein file (same as fasta but with different extension) \n",
    "* list of amino acids for each transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### pseudo python code\n",
    "\n",
    "#import packages\n",
    "#open infiles to read\n",
    "#open codon map to read\n",
    "#open outfiles to write\n",
    "#read codonmap into a dictionary\n",
    "#define the function to translate the base sequence column into the amino acid column\n",
    "#define the function to group base sequence into codons\n",
    "#define the function to translate the codons using the dictionary\n",
    "    #for:\n",
    "        #if the amino acid is Stop, stop reading the sequence\n",
    "        #else keep translating\n",
    "    #return the amino acid string\n",
    "#define the start codon regex\n",
    "#for:\n",
    "    #if line begins with >\n",
    "        #write line to the outfile\n",
    "    #else\n",
    "        #find start codon using regex and delete everything prior to that codon\n",
    "        #use the codon translating function\n",
    "        #write line to outfile\n",
    "#repeat for loop in each each infile and write to corresponding outfiles\n",
    "#close all infiles, outfiles, and the codonmap\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##actual python code \n",
    "\n",
    "#load packages\n",
    "import numpy\n",
    "import pandas\n",
    "import re\n",
    "from sys import argv\n",
    "from itertools import takewhile\n",
    "\n",
    "#openfiles\n",
    "infile1 = open(\"control1.fasta\",\"r\")\n",
    "infile2 = open(\"control2.fasta\",\"r\")\n",
    "infile3 = open(\"obese1.fasta\",\"r\")\n",
    "infile4 = open(\"obese2.fasta\",\"r\")\n",
    "codonmap = open(\"codonmap.txt\",\"r\")\n",
    "\n",
    "#create and open files for output\n",
    "outfile1 = open(\"control1_protein\",\"w\")\n",
    "outfile2 = open(\"control2_protein\",\"w\")\n",
    "outfile3 = open(\"obese1_protein\",\"w\")\n",
    "outfile4 = open(\"obese2_protein\",\"w\")\n",
    "\n",
    "#create dictionary\n",
    "d = {}\n",
    "for line in codonmap:\n",
    "    (val,key) = line.split()\n",
    "    d[str(key)] = val\n",
    "\n",
    "def translateCodon (x):\n",
    "    if x in d:\n",
    "        return d[x]\n",
    "\n",
    "def splitCodons(sequence):\n",
    "    result = []\n",
    "    for i in range(1, len(sequence)+1, 3):\n",
    "        result.append(sequence[i:i+3])\n",
    "    return result\n",
    "    \n",
    "def translateSequence(sequence):\n",
    "    codons = splitCodons(sequence)\n",
    "    aaString = 'M'\n",
    "    for codon in codons:\n",
    "        if translateCodon(codon) == 'Stop':\n",
    "            return aaString\n",
    "        else:\n",
    "            aaString += translateCodon(codon)\n",
    "    return aaString\n",
    "\n",
    "r1=r\"([ATCG]{3,3})+?(ATG)\"\n",
    "\n",
    "for line in infile1:\n",
    "\tline = line.strip()\n",
    "\tif line[0] == \">\":\n",
    "\t    outfile1.write(line + \"\\n\")\n",
    "\telse:\n",
    "\t    start = re.sub(r1,\"ATG\",line,count=1)\n",
    "\t    aminoacids = translateSequence(start)\n",
    "        outfile1.write(aminoacids + \"\\n\")\n",
    "\n",
    "for line in infile2:\n",
    "\tline = line.strip()\n",
    "\tif line[0] == \">\":\n",
    "\t    outfile2.write(line + \"\\n\")\n",
    "\telse:\n",
    "\t    start = re.sub(r1,\"ATG\",line,count=1)\n",
    "\t    aminoacids = translateSequence(start)\n",
    "        outfile2.write(aminoacids + \"\\n\")\n",
    "\n",
    "for line in infile3:\n",
    "\tline = line.strip()\n",
    "\tif line[0] == \">\":\n",
    "\t    outfile3.write(line + \"\\n\")\n",
    "\telse:\n",
    "\t    start = re.sub(r1,\"ATG\",line,count=1)\n",
    "\t    aminoacids = translateSequence(start)\n",
    "        outfile3.write(aminoacids + \"\\n\")\n",
    "\n",
    "for line in infile4:\n",
    "\tline = line.strip()\n",
    "\tif line[0] == \">\":\n",
    "\t    outfile4.write(line + \"\\n\")\n",
    "\telse:\n",
    "\t    start = re.sub(r1,\"ATG\",line,count=1)\n",
    "\t    #short = re.sub(r'.*M','M',start)\n",
    "\t    aminoacids = translateSequence(start)\n",
    "        outfile4.write(aminoacids + \"\\n\")\n",
    "\t\n",
    "#close files \n",
    "infile1.close()\n",
    "infile2.close()\n",
    "infile3.close()\n",
    "infile4.close()\n",
    "outfile1.close()\n",
    "outfile2.close()\n",
    "outfile3.close()\n",
    "outfile4.close()\n",
    "codonmap.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Notes\n",
    "this code translated the RNAseq fasta files:\n",
    "* 'contro1.fasta'\n",
    "* 'control2.fasta'\n",
    "* 'obese1.fasta'\n",
    "* 'obese2.fasta'\n",
    "into amino acid sequences and saved the files as:\n",
    "* 'control1.protein'\n",
    "* 'control2.protein'\n",
    "* 'obese1.protein'\n",
    "* 'obese2.protein'\n",
    "all of these files, along with the codon map used for the dicitonary and the python script used to accomplish the task are locate in the 'RNAseq_data' file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5\n",
    "Built a HMM of the 6 transcript proteins, search translated RNAseq files \n",
    "* Muscle alignment --> hmmbuild --> hmmsearch\n",
    "* use bash script to loop over files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Psuedo code\n",
    "\n",
    "#use muscle to create alignments\n",
    "muscle -in <inputfule> -out <outputfile> #input file is the protein fasta file from NCBI\n",
    "    #repeat for each protein (6) for loop here\n",
    "    \n",
    "#use hmm build to build the markov model\n",
    "hmmbuild <hmm_file_out> <MSAfile> #MSAfile is the output of the muscle alignment, hmm_file_out builds it\n",
    "    #repeat for each protein (6) for loop here too\n",
    "\n",
    "#loop through each model, loop through each treatment, concatenate to build one table for each treatment\n",
    "for files in proteinmodels\n",
    "do\n",
    "    for treatment in 'translated RNAseq files'\n",
    "    do    \n",
    "        hmmsearch --tblout $files.$hmms.hits $files $hmms #searches first protein, repeats for each protein and treatment\n",
    "        cat $files.$hmms.hits >> $files.hits.table #adds protein hits to new files for each treatment, appends \n",
    "    done\n",
    "done\n",
    "\n",
    "#for these steps we need the protein fasta files, the converted RNAseq files, the bioinformatic tools, \n",
    "#and the necessary script in the appropriate repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#builds hidden markov models for each protein and searches translated RNAseq files for each protein\n",
    "#have to have muscle, hmmbuild, and hmmmsearch files in repo\n",
    "\n",
    "#muscle alignment\n",
    "for proteins in protein*.fasta #loops through all protein files\n",
    "do \n",
    "\t./muscle -in $proteins -out $proteins.align\n",
    "done\n",
    "#build models\n",
    "for align in protein*.fasta.align #builds hmms for each protein alignment\n",
    "do\n",
    "\t./hmmbuild $align.hmm $align\n",
    "done\n",
    "#search rnaseq files for protein models\n",
    "for models in protein*.fasta.align.hmm #loops through models\n",
    "do\n",
    "\tfor treatment in *.protein #Loops through treatments\n",
    "\tdo\n",
    "\t\t./hmmsearch --tblout $treatment.hits $models $treatment #creates table for each transcript\n",
    "\t\tcat $treatment.hits >> $treatment.hits.table #appends to table\n",
    "\tdone\n",
    "done\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Notes\n",
    "For this code to work we have 3 repos for each time we wanted to build and search the protein models\n",
    "These are located in the following repositories:\n",
    "* 'Rodent_HMMs'\n",
    "* '\n",
    "*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6\n",
    "We Graphically compared expression levels across groups\n",
    "* Qualitatively compare results to Kuhns & Pluznick 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pseudo code\n",
    "\n",
    "# cat all hits files for each transcript\n",
    "# generate a table of counts - transcript, model, hits\n",
    "# read table into dataframe\n",
    "# 4 graphs - subset data (one for each sample, with 6 models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#actual unix code (see script Comparions.sh) in the 'Plots' repo\n",
    "\n",
    "grep -v '#' control1.protein.hits.table_rodent | awk '{print $1,$3}' | uniq -c | awk '{print $1,$2,$3}' > Control1Counts.txt\n",
    "grep -v '#' control2.protein.hits.table_rodent | awk '{print $1,$3}' | uniq -c | awk '{print $1,$2,$3}' > Control2Counts.txt\n",
    "grep -v '#' obese1.protein.hits.table_rodent | awk '{print $1,$3}' | uniq -c | awk '{print $1,$2,$3}' > Obese1Counts.txt\n",
    "grep -v '#' obese2.protein.hits.table_rodent | awk '{print $1,$3}' | uniq -c | awk '{print $1,$2,$3}' > Obese2Counts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#actual python code (see script ComparisonGraphs.py) in the 'Plots' repo\n",
    "\n",
    "import pandas\n",
    "from plotnine import *\n",
    "\n",
    "C1data=pandas.read_table(\"Control1Counts.txt\")\n",
    "C2data=pandas.read_table(\"Control2Counts.txt\")\n",
    "O1data=pandas.read_table(\"Obese1Counts.txt\")\n",
    "O2data=pandas.read_table(\"Obese2Counts.txt\")\n",
    "\n",
    "C1data.columns=['Count','sample','Model']\n",
    "C2data.columns=['Count','sample','Model']\n",
    "O1data.columns=['Count','sample','Model']\n",
    "O2data.columns=['Count','sample','Model']\n",
    "\n",
    "ggplot(C1data,aes(x='Model',y='Count'))+geom_col(size=20)+ggtitle('Control1 Transcript Counts')+ theme ( axis_text_x = element_text ( angle = 90 ))\n",
    "ggplot(C2data,aes(x='Model',y='Count'))+geom_col(size=20)+ggtitle('Control2 Transcript Counts')+ theme ( axis_text_x = element_text ( angle = 90 ))\n",
    "ggplot(O1data,aes(x='Model',y='Count'))+geom_col(size=20)+ggtitle('Obese1 Transcript Counts')+ theme ( axis_text_x = element_text ( angle = 90 ))\n",
    "ggplot(O2data,aes(x='Model',y='Count'))+geom_col(size=20)+ggtitle('Obese2 Transcript Counts')+ theme ( axis_text_x = element_text ( angle = 90 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates 4 histograms (one for each sample type) with the 6 protein models. These can be seen in the \"plots\" repository as C1CountPlot.png, C2CountPlot.png, O1CountPlot.png, O2CountPlot.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Manual test\n",
    "\n",
    "#Using the following unix code and excel, we also generated a csv file containing information regarding the frequency of hits\n",
    "#see the 'expression.script' in the 'Plots' repository:\n",
    "cat control1.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein1'\n",
    "cat control1.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein2'\n",
    "cat control1.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein3'\n",
    "cat control1.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein4'\n",
    "cat control1.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein5'\n",
    "cat control1.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein6'\n",
    "cat control2.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein1'\n",
    "cat control2.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein2'\n",
    "cat control2.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein3'\n",
    "cat control2.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein4'\n",
    "cat control2.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein5'\n",
    "cat control2.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein6'\n",
    "cat obese1.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein1'\n",
    "cat obese1.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein2'\n",
    "cat obese1.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein3'\n",
    "cat obese1.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein4'\n",
    "cat obese1.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein5'\n",
    "cat obese1.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein6'\n",
    "cat obese2.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein1'\n",
    "cat obese2.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein2'\n",
    "cat obese2.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein3'\n",
    "cat obese2.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein4'\n",
    "cat obese2.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein5'\n",
    "cat obese2.protein.hits.table_nonmammalian | grep -v '#' | grep -c 'protein6'\n",
    "\n",
    "\n",
    "#after generating the table, we then plotted the table in python using the 'quickdirtyplot.py' located in the 'Plots' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from plotnine import *\n",
    "data=pandas.read_csv(\"expressionlevels.csv\")\n",
    "plot=ggplot(data,aes(x='Protein',y='ExpressionLevel',color='Treatment'))\n",
    "plot+geom_jitter(width=.1,height=.3,alpha=.5,size=5)+theme_classic()+ggtitle('Protein Expression Levels for Each Treatment')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates the graph seen in the image 'expressionlevels.png' in the 'Plots' repository \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 models are abbreviated Lhx2,Gsta2,Slc7a12,Ptpn5,Atp12a,Synpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualitative comparison to Kuhns and Ploznick 2017\n",
    "Our results mirror those of Kuhns and Ploznick. Both Obese samples show highest fold change in Synpr, followed by Lhx2, Atp12a, and Ptpn5. Greatest fold decrease is seen in genes Slc7a12 and Gsta2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Exploration\n",
    "#### 1. Change the 'Optimize for' option\n",
    "##### Qualitatively, how do discontinuous megablast (more disimilar) and blastn (somewhat similar) change your table of BLAST hits?\n",
    "The top hits for each of these blasts tend to remain the same. However, when you make the blast more disimilar (discontinous megablast) or only somewhat similar (blastn) the range of results changes. You get more sequences matching to other species and the quality of matches (e value of matches with lower max scores) also decreases. \n",
    "#### 2. Explore the effects of phylogenetic relatedness of your amino acid sequences on the performance of your HMM model\n",
    "##### What happens if you build your HMM protein model using more distantly related mammals (e.g. primates)?\n",
    "##### Do you still get the same quality hits if your HMM protein model is based on non-mammalian sequences?\n",
    "Generally, you can make some assumptions that E-value scores tend to increase as phylogenetic relationship decreases. Looking at the quality hits of other HMM protein models (between nonmammalian, rodents, and primates) shows that E-values are typically lower in nonmammals than in the mammals (rodents and primates). However, this was not always the case when you compared the rodent hmms to the primate hmms with the E-values increasing for one protein or decreasing for others. Therefore, for more closely related species you may get different e-value scores (quality hits) for each protein. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
